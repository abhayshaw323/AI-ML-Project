{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e0dc34",
   "metadata": {},
   "source": [
    "Q 42. What evaluation metrics are more suitable for logistic regression than accuracy?\n",
    "\n",
    "Accuracy alone is not a dependable measure for Logistic Regression, especially with imbalanced datasets or when the cost of different errors differs. Logistic Regression gives probabilities, so metrics that assess class performance and the quality of those probabilities work better.\n",
    "Precision measures how many predicted positives are actually positive, which is helpful when false positives are a concern. Recall measures how many actual positives the model correctly identifies, which is crucial when false negatives are expensive. The F1-Score combines precision and recall and is useful for imbalanced data.These metrics provide a more informative and robust evaluation than accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c1e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8456989220316136\n",
      "Recall: 0.8462121212121212\n",
      "F1 Score: 0.8455368812137377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 5000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=5000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"weather_classification_data.csv\")\n",
    "\n",
    "# Encode all categorical columns\n",
    "label_encoders = {}\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop(\"Weather Type\", axis=1)\n",
    "y = data[\"Weather Type\"]\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
